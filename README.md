### NeRFStudio-giga

(GAIIC) giga-rendering: giga-pixel novel view synthesis competition 4th place solution. Implementation based on [nerfstudio](https://github.com/nerfstudio-project/nerfstudio). The other two contributors are [Dinnger](https://github.com/Dinngger) and [funnymudpeer](https://github.com/funnymudpeer).

The ranks can be found in [giga-vision's leaderboard for rendering challenge](https://gigavision.cn/track/track?nav=Sparse%20rendering&type=nav). Our presentation slides can be found [here](https://docs.google.com/presentation/d/16zcceAIQLTjLUsLQfgxJlnt-Mq_6Hl5w/edit?usp=sharing&ouid=113113092240480704238&rtpof=true&sd=true) 
![Screenshot 2023-06-19 111113](https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/a9b36352-49b2-4bec-8167-a7283beca0c7)


#### Part of the results

DayaTemple trained for 10min:

https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/8c188691-bdf0-487c-8ebc-f7e50b2c571b

ScienceSquare full model, RGB and depth rendering:

https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/ce8ccd3b-6bfd-4b6c-aa1c-b6d66d36cd78

Memorialhall full model, RGB and depth rendering:

https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/cb8c3c43-5b93-46b6-af53-0ee5f4857866

Detail zoom in (in test views). Our model does aggressive pose optimization and re-estimation, therefore the details are rich:


https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/9a061975-d3d2-4a21-878c-16ad17107da8





