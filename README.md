### NeRFStudio-giga

(GAIIC) giga-rendering: giga-pixel novel view synthesis competition 4th place solution. Implementation based on [nerfstudio](https://github.com/nerfstudio-project/nerfstudio). The other two contributors are [Dinnger](https://github.com/Dinngger) and [funnymudpeer](https://github.com/funnymudpeer).

The ranks can be found in [giga-vision's leaderboard for rendering challenge](https://gigavision.cn/track/track?nav=Sparse%20rendering&type=nav). Our presentation slides can be found [here](https://docs.google.com/presentation/d/16zcceAIQLTjLUsLQfgxJlnt-Mq_6Hl5w/edit?usp=sharing&ouid=113113092240480704238&rtpof=true&sd=true) 
![Screenshot 2023-06-19 111113](https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/240cb6e5-765b-4a4c-82a2-194e2e1a7a40)



#### Part of the results

DayaTemple trained for 10min:



https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/ce904944-4854-4e44-b5d4-23f7bc74f9ca



ScienceSquare full model, RGB and depth rendering:



https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/ed175a46-6fe5-4a0a-ae6c-6f6b3f935555


Memorialhall full model, RGB and depth rendering:



https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/0ff7ffdc-0edb-4642-9519-e4e63228bf25



Detail zoom in (in test views). Our model does aggressive pose optimization and re-estimation, therefore the details are rich:




https://github.com/Enigmatisms/nerfstudio-giga/assets/46109954/590a58af-4de3-4156-8b68-b2cb3eda4bf2







